{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1YnU-uv09DQ"
      },
      "outputs": [],
      "source": [
        "# === SECTION 1: SHAP FEATURE IMPORTANCE GRAPHS===\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Use your trained MLP as the winner model\n",
        "winner_model = model_mlp\n",
        "\n",
        "# ✅ Use the IQR-filtered + scaled datasets from your previous cells\n",
        "background = X_Train.sample(100, random_state=42)\n",
        "X_shap = X_Test.sample(100, random_state=42)\n",
        "\n",
        "# Wrap predict_proba so it returns ONLY the probability for class 1\n",
        "def mlp_prob_class1(x):\n",
        "    # SHAP may pass numpy arrays; convert back to DataFrame with correct columns\n",
        "    if isinstance(x, np.ndarray):\n",
        "        x = pd.DataFrame(x, columns=background.columns)\n",
        "    return winner_model.predict_proba(x)[:, 1]\n",
        "\n",
        "# KernelExplainer for tabular NN\n",
        "explainer = shap.KernelExplainer(mlp_prob_class1, background)\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer.shap_values(X_shap)\n",
        "\n",
        "# Handle possible list output\n",
        "sv = shap_values[0] if isinstance(shap_values, list) else shap_values\n",
        "\n",
        "# ----------------------------\n",
        "# ✅ MOST IMPORTANT FEATURES\n",
        "# ----------------------------\n",
        "importance = np.abs(sv).mean(axis=0)  # mean(|SHAP|) per feature\n",
        "feat_imp = pd.Series(importance, index=X_shap.columns).sort_values(ascending=False)\n",
        "\n",
        "top_n = 5\n",
        "print(f\"\\nTop {top_n} Most Important Features (mean(|SHAP|)):\\n\")\n",
        "print(feat_imp.head(top_n))\n",
        "\n",
        "# Optional: bar chart ranking (global importance)\n",
        "shap.summary_plot(sv, X_shap, plot_type=\"bar\", feature_names=X_shap.columns, color=\"#FF6F61\", show=True)\n",
        "\n",
        "# Your original beeswarm summary plot (like the graph you showed)\n",
        "shap.summary_plot(\n",
        "    sv,\n",
        "    X_shap,\n",
        "    feature_names=X_shap.columns,\n",
        "    cmap=\"viridis\",\n",
        "    show=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === SECTION 2:SHAP Decision Plot for Heart Disease PRESENCE & ABSENCE ===\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get predictions for the specific sample set used in SHAP\n",
        "#    We need to know which rows correspond to \"High Risk\" and \"Low Risk\"\n",
        "probs_shap = winner_model.predict_proba(X_shap)[:, 1]\n",
        "\n",
        "# 2. Identify indices for the two cases\n",
        "# Case A: Heart Disease Presence (Find the patient with Highest Probability)\n",
        "idx_presence = np.argmax(probs_shap)\n",
        "\n",
        "# Case B: Heart Disease Absence (Find the patient with Lowest Probability)\n",
        "idx_absence = np.argmin(probs_shap)\n",
        "\n",
        "# 3. Handle Expected Value (Base Value)\n",
        "# KernelExplainer sometimes wraps expected_value in a list/array\n",
        "base_value = explainer.expected_value\n",
        "if isinstance(base_value, (list, np.ndarray)):\n",
        "    base_value = base_value[0]\n",
        "\n",
        "print(f\"Base Value (Average Prediction): {base_value:.4f}\")\n",
        "print(f\"Plotting Case 1 (Presence): Index {idx_presence}, Prob: {probs_shap[idx_presence]:.4f}\")\n",
        "print(f\"Plotting Case 2 (Absence):  Index {idx_absence}, Prob: {probs_shap[idx_absence]:.4f}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# GRAPH 1: SHAP Decision Plot for Heart Disease PRESENCE\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\n--- 1. SHAP Decision Plot: Heart Disease Presence ---\")\n",
        "plt.figure()  # Create a new figure\n",
        "shap.decision_plot(\n",
        "    base_value,\n",
        "    sv[idx_presence],\n",
        "    X_shap.iloc[idx_presence],\n",
        "    feature_names=X_shap.columns.tolist(),\n",
        "    link='logit',  # Optional: converts log-odds to probabilities (0-1 scale)\n",
        "    show=False     # Keep false to allow title addition\n",
        ")\n",
        "plt.title(f\"Decision Plot: Heart Disease Presence (Prob: {probs_shap[idx_presence]:.2f})\", fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# GRAPH 2: SHAP Decision Plot for Heart Disease ABSENCE\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\n--- 2. SHAP Decision Plot: Heart Disease Absence ---\")\n",
        "plt.figure()  # Create a new figure\n",
        "shap.decision_plot(\n",
        "    base_value,\n",
        "    sv[idx_absence],\n",
        "    X_shap.iloc[idx_absence],\n",
        "    feature_names=X_shap.columns.tolist(),\n",
        "    link='logit',\n",
        "    show=False\n",
        ")\n",
        "plt.title(f\"Decision Plot: Heart Disease Absence (Prob: {probs_shap[idx_absence]:.2f})\", fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YjukAK_61iF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === SECTION 3: LIME INSTANCE EXPLANATION ===\n",
        "# For Patient-15\n",
        "\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "\n",
        "# 1. Setup the Explainer\n",
        "# LIME needs to know the distribution of your training data to make \"fake\" perturbations\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=np.array(X_Train),      # Your training data\n",
        "    feature_names=X_Train.columns,  # Name of your columns (Age, Sex_M, etc.)\n",
        "    class_names=['Normal', 'Heart Disease'], # The labels 0 and 1\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# 2. Pick a Specific Patient to Explain\n",
        "# Let's pick patient #10 from the Test Set (you can change this number)\n",
        "patient_idx = 15\n",
        "patient_data = X_Test.iloc[patient_idx]\n",
        "true_status = \"Heart Disease\" if Y_Test.iloc[patient_idx] == 1 else \"Normal\"\n",
        "\n",
        "print(f\"--- Explaining Patient #{patient_idx} ---\")\n",
        "print(f\"Actual Truth: {true_status}\")\n",
        "\n",
        "# 3. Generate the Explanation\n",
        "# We ask the MLP model: \"What is the probability for this patient?\"\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=patient_data,\n",
        "    predict_fn=model_mlp.predict_proba # We pass the MLP's prediction function\n",
        ")\n",
        "\n",
        "# 4. Show the Plot\n",
        "exp.show_in_notebook(show_table=True)\n",
        "\n",
        "# Optional: Save as HTML file to include in your paper presentation\n",
        "exp.save_to_file('LIME_Explanation_Patient_15.html')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# Extract data\n",
        "explanation_data = exp.as_list()\n",
        "feature_names = [x[0] for x in explanation_data]\n",
        "feature_vals = [x[1] for x in explanation_data]\n",
        "\n",
        "# --- THIS IS THE LINE TO EDIT FOR COLORS ---\n",
        "# Currently set to Soft Coral (#FF6F61) and Pastel Teal (#48C9B0)\n",
        "colors = ['#FF6F61' if x > 0 else '#48C9B0' for x in feature_vals]\n",
        "# -------------------------------------------\n",
        "\n",
        "# Create Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, feature_vals, color=colors, edgecolor='white', height=0.7)\n",
        "\n",
        "# Styling\n",
        "plt.title(f\"LIME Analysis: Patient #{patient_idx} (True: {true_status})\", fontsize=14, fontweight='bold', pad=20)\n",
        "plt.xlabel(\"Contribution to Prediction\", fontsize=12)\n",
        "plt.axvline(0, color='grey', linewidth=0.8, linestyle='--')\n",
        "plt.grid(axis='x', linestyle=':', alpha=0.6)\n",
        "\n",
        "# Legend\n",
        "legend_elements = [\n",
        "    Patch(facecolor='#FF6F61', label='Increases Risk(Heart Disease)'),\n",
        "    Patch(facecolor='#48C9B0', label='Decreases Risk(Normal)')\n",
        "]\n",
        "plt.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X3jKuPED16Y2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}