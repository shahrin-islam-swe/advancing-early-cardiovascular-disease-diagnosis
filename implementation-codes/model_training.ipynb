{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFbG6yW6lCdx"
      },
      "outputs": [],
      "source": [
        "# === SECTION 1: Training 5 BASE MODELS Without Balancing===\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# 1. Load Data\n",
        "df = pd.read_csv('heart.csv')\n",
        "\n",
        "# 2. Preprocessing\n",
        "le = LabelEncoder()\n",
        "categorical_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
        "for col in categorical_cols:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "X = df.drop('HeartDisease', axis=1)\n",
        "y = df['HeartDisease']\n",
        "\n",
        "# 3. Split (SEED 369)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=369)\n",
        "\n",
        "# 4. Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 5. Define Models (ALL SEED 369)\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=369),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=369),\n",
        "    \"LightGBM\": LGBMClassifier(random_state=369, verbose=-1),\n",
        "    \"MLP\": MLPClassifier(max_iter=1000, random_state=369),\n",
        "    \"SVC\": SVC(probability=True, random_state=369)\n",
        "}\n",
        "\n",
        "# 6. Run & Print\n",
        "print(f\"{'Model':<15} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1 Score':<10}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"{name:<15} | {acc:.4%}   | {prec:.4%}   | {rec:.4%}   | {f1:.4%}\")\n",
        "\n",
        "print(\"-\" * 65)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === SECTION 2: TRAIN SINGLE MODELS WITH OPTIMAL BALANCING ===\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Balancing Libraries\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "# 1. Load Data\n",
        "df = pd.read_csv('heart.csv')\n",
        "\n",
        "# 2. Preprocessing\n",
        "le = LabelEncoder()\n",
        "categorical_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
        "for col in categorical_cols:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "X = df.drop('HeartDisease', axis=1)\n",
        "y = df['HeartDisease']\n",
        "\n",
        "# 3. Split (SEED 369)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=369)\n",
        "\n",
        "# 4. Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 5. Define Models (ALL SEED 369)\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=369),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=369),\n",
        "    \"LightGBM\": LGBMClassifier(random_state=369, verbose=-1),\n",
        "    \"MLP\": MLPClassifier(max_iter=1000, random_state=369),\n",
        "    \"SVC\": SVC(probability=True, random_state=369)\n",
        "}\n",
        "\n",
        "# 6. Define Techniques (ALL SEED 369 where applicable)\n",
        "# Note: TomekLinks does not use a random_state\n",
        "samplers = {\n",
        "    \"SMOTE\": SMOTE(random_state=369),\n",
        "    \"SMOTETomek\": SMOTETomek(random_state=369),\n",
        "    \"ADASYN\": ADASYN(random_state=369),\n",
        "    \"Tomek Links\": TomekLinks(),\n",
        "    \"SMOTEENN\": SMOTEENN(random_state=369)\n",
        "}\n",
        "\n",
        "# 7. Run Experiment\n",
        "print(f\"{'Model':<15} | {'Technique':<12} | {'Accuracy':<9} | {'Precision':<9} | {'Recall':<9} | {'F1 Score':<9}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    for tech_name, sampler in samplers.items():\n",
        "        try:\n",
        "            # A. Balance Data (Training Only)\n",
        "            X_res, y_res = sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "            # B. Train Model (Reset model each time to be safe)\n",
        "            # We must re-initialize the model to ensure it learns from scratch\n",
        "            model.fit(X_res, y_res)\n",
        "\n",
        "            # C. Predict\n",
        "            y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "            # D. Metrics\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            prec = precision_score(y_test, y_pred)\n",
        "            rec = recall_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "            print(f\"{model_name:<15} | {tech_name:<12} | {acc:.4f}    | {prec:.4f}    | {rec:.4f}    | {f1:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"{model_name:<15} | {tech_name:<12} | FAILED: {e}\")\n",
        "\n",
        "    print(\"-\" * 75) # Separator between models\n"
      ],
      "metadata": {
        "id": "F6jH9bXSl0Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === SECTION 3: SINGLE MODEL PERFORMANCE METRICS ===\n",
        "# Confusion Matrix & ROC Curves for all models\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Balancing\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. SETUP DATA (Seed 369)\n",
        "# ---------------------------------------------------------\n",
        "df = pd.read_csv('heart.csv')\n",
        "le = LabelEncoder()\n",
        "for col in ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "X = df.drop('HeartDisease', axis=1)\n",
        "y = df['HeartDisease']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=369)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. DEFINE CONFIGURATIONS\n",
        "# ---------------------------------------------------------\n",
        "# We will define the models and a list of balancers to check\n",
        "models_dict = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=369),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=369),\n",
        "    \"LightGBM\": LGBMClassifier(random_state=369, verbose=-1),\n",
        "    \"MLP\": MLPClassifier(max_iter=1000, random_state=369),\n",
        "    \"SVM\": SVC(probability=True, random_state=369)\n",
        "}\n",
        "\n",
        "balancers = {\n",
        "    \"SMOTE\": SMOTE(random_state=369),\n",
        "    \"SMOTETomek\": SMOTETomek(random_state=369),\n",
        "    \"ADASYN\": ADASYN(random_state=369),\n",
        "    \"Tomek Links\": TomekLinks(),\n",
        "    \"SMOTEENN\": SMOTEENN(random_state=369)\n",
        "}\n",
        "\n",
        "# Custom Colors\n",
        "colors_teal = [\"#F2FBF9\", \"#48C9B0\", \"#00796B\"]\n",
        "cmap_custom = LinearSegmentedColormap.from_list(\"CustomTeal\", colors_teal)\n",
        "roc_color = '#FF6F61' # Coral\n",
        "\n",
        "# Storage for the Combined ROC Plot\n",
        "roc_data = {}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. LOOP, TRAIN, & PLOT\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"\\nProcessing {model_name}...\")\n",
        "\n",
        "    # --- A. Find the Best Balancer for this Model ---\n",
        "    # We run all 5 and pick the one that matches your target accuracy (or gives max)\n",
        "    best_acc = 0\n",
        "    best_pred = None\n",
        "    best_probs = None\n",
        "    best_tech_name = \"\"\n",
        "\n",
        "    for tech_name, sampler in balancers.items():\n",
        "        try:\n",
        "            # Resample Training Data Only\n",
        "            X_res, y_res = sampler.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "            # Train (Re-initialize to ensure fresh start)\n",
        "            if model_name == \"Random Forest\": clf = RandomForestClassifier(random_state=369)\n",
        "            elif model_name == \"XGBoost\": clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=369)\n",
        "            elif model_name == \"LightGBM\": clf = LGBMClassifier(random_state=369, verbose=-1)\n",
        "            elif model_name == \"MLP\": clf = MLPClassifier(max_iter=1000, random_state=369)\n",
        "            elif model_name == \"SVM\": clf = SVC(probability=True, random_state=369)\n",
        "\n",
        "            clf.fit(X_res, y_res)\n",
        "            preds = clf.predict(X_test_scaled)\n",
        "            probs = clf.predict_proba(X_test_scaled)[:, 1]\n",
        "            acc = accuracy_score(y_test, preds)\n",
        "\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                best_pred = preds\n",
        "                best_probs = probs\n",
        "                best_tech_name = tech_name\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"   > Best Result: {best_acc:.4%} using {best_tech_name}\")\n",
        "\n",
        "    # Store for Combined Plot\n",
        "    roc_data[model_name] = (y_test, best_probs, best_acc)\n",
        "\n",
        "    # --- B. Generate Confusion Matrix Plot ---\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    cm = confusion_matrix(y_test, best_pred)\n",
        "\n",
        "    # Labels with Counts & Percentages\n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
        "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "\n",
        "    sns.heatmap(cm, annot=labels, fmt='', cmap=cmap_custom, cbar=False,\n",
        "                annot_kws={\"fontsize\":12, \"fontweight\":\"bold\"})\n",
        "\n",
        "    plt.title(f'Confusion Matrix: {model_name}', fontsize=14, fontweight='bold', pad=15)\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.ylabel('Actual Label', fontsize=12)\n",
        "    plt.xticks([0.5, 1.5], ['Normal', 'Heart Disease'])\n",
        "    plt.yticks([0.5, 1.5], ['Normal', 'Heart Disease'])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- C. Generate Individual ROC Plot ---\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    fpr, tpr, _ = roc_curve(y_test, best_probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.plot(fpr, tpr, color=roc_color, lw=3, label=f'AUC = {roc_auc:.4f}')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title(f'ROC Curve: {model_name}', fontsize=14, fontweight='bold', pad=15)\n",
        "    plt.legend(loc=\"lower right\", fontsize=11)\n",
        "    plt.grid(alpha=0.3, linestyle=':')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. GENERATE COMBINED ROC PLOT (The 6th ROC Graph)\n",
        "# ---------------------------------------------------------\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Define distinct line styles/colors for the combined plot to differentiate\n",
        "styles = ['-', '--', '-.', ':', '-']\n",
        "markers = [None, None, None, None, 'o']\n",
        "colors_combined = ['#FF6F61', '#48C9B0', '#5DADE2', '#F4D03F', '#AF7AC5'] # Coral, Teal, Blue, Gold, Purple\n",
        "\n",
        "for i, (name, (y_true, y_prob, acc)) in enumerate(roc_data.items()):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr,\n",
        "             label=f'{name} (AUC={roc_auc:.3f})',\n",
        "             color=colors_combined[i],\n",
        "             linestyle=styles[i],\n",
        "             lw=2.5)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('Combined ROC Analysis: All Models', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.legend(loc=\"lower right\", fontsize=11, frameon=True, fancybox=True, framealpha=0.9)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Axeymb4wmJ2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === SECTION 4: Comaprison Bar Plot of test accuracies of the 5 models with their best balancing results ===\n",
        "\n",
        "# 1. Create a dictionary with your model names and their Test Accuracy scores\n",
        "#(Using the exact scores from your Kaggle run)\n",
        "model_accuracies = {\n",
        "    'Random Forest': 90.22,\n",
        "    'XGBoost': 92.93,\n",
        "    'LightGBM': 92.93,\n",
        "    'MLP Classifier': 92.38,\n",
        "    'SVC': 92.38,\n",
        "}\n",
        "\n",
        "# 2. Convert the dictionary to a pandas DataFrame for easy plotting\n",
        "scores_df = pd.DataFrame(list(model_accuracies.items()), columns=['Model', 'Test Accuracy'])\n",
        "\n",
        "# 3. Sort the DataFrame by accuracy in descending order\n",
        "scores_df = scores_df.sort_values(by='Test Accuracy', ascending=False)\n",
        "\n",
        "# 4. Create the bar plot\n",
        "plt.figure(figsize=(5, 7)) # Adjust size as needed\n",
        "# We use a horizontal bar plot (sns.barplot with y='Model')\n",
        "# This is much easier to read when you have many model names\n",
        "sns.barplot(x='Test Accuracy', y='Model', data=scores_df, palette='crest')\n",
        "\n",
        "# 5. Add titles and labels\n",
        "plt.title('Comparison of All 5 Models (Test Accuracy)', fontsize=16)\n",
        "plt.xlabel('Test Accuracy (%)', fontsize=12)\n",
        "plt.ylabel('Model', fontsize=12)\n",
        "\n",
        "# 6. Set the x-axis limits to \"zoom in\" on the differences\n",
        "# (Most scores are between 85% and 94%)\n",
        "plt.xlim(80, 94)\n",
        "\n",
        "# 7. Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LVMkBElRnEH0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}